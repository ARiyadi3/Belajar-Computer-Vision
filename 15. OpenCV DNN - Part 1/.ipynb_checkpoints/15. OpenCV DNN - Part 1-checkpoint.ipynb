{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV DNN - Part 1\n",
    "\n",
    "- OpenCV DNN\n",
    "- Yolo Darknet\n",
    "- OpenCV DNN Yolo\n",
    "- Train Yolo Model with Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original Source : https://github.com/alitourani/yolo-license-plate-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro Deep Learning\n",
    "\n",
    "- “#1 Pengenalan Machine Learning”  https://medium.com/@yunusmuhammad007/pengenalan-machine-learning-2320b5ca7266\n",
    "- “#2 Supervised VS Unsupervised VS Reinforcement ML”  https://link.medium.com/wEcGRj3gq5\n",
    "- “#3 Machine Learning Evaluation”  https://link.medium.com/qJ9Kd26gq5\n",
    "- “#4 Alat dan Bahan untuk Machine Learning”  https://medium.com/@yunusmuhammad007/3-alat-dan-bahan-untuk-machine-learning-92c717286624\n",
    "- “#5 Basic Python Programming”  https://medium.com/@yunusmuhammad007/5-basic-python-programming-87c89e1d0d3e\n",
    "- “#6 Artificial Neural Network (ANN) — Part 1 (Pengenalan)”  https://link.medium.com/TbaRUcJZv5\n",
    "- “#7 Artificial Neural Network (ANN) — Part 2 (Single Layer Perceptron)”  https://link.medium.com/kpBiXHBdz5\n",
    "- “#8 Artificial Neural Network (ANN) — Part 3 (Teori Dasar Multi Layer Perceptron Backpropagation)”  https://link.medium.com/D7rAjn69F6\n",
    "- “#9 Artificial Neural Network (ANN) — Part 4 (MLP Backpropagation Time Series Forecasting…”  https://link.medium.com/s2ZZFy89F6\n",
    "- “#10 Artificial Neural Network (ANN) — Part 5 (Time Series Forecasting ISPU CO DKI Jakarta…”  https://link.medium.com/ccHKkBaaG6\n",
    "- “#11 Artificial Neural Network (ANN) — Part 6 Konsep Dasar Convolutional Neural Network (CNN)”  https://link.medium.com/gy2J4beaG6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV DNN\n",
    "\n",
    "- Compatibility : > OpenCV 3.3\n",
    "- Wiki : https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "- Since OpenCV 3.1 there is DNN module in the library that implements **forward pass** (inferencing) with deep networks, **pre-trained**using some popular deep learning frameworks.\n",
    "- The supported frameworks:\n",
    "    - Caffe\n",
    "    - TensorFlow\n",
    "    - Torch\n",
    "    - Darknet (Yolo)\n",
    "    - Models in ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo (neural networks for object detection)\n",
    "\n",
    "https://github.com/AlexeyAB/darknet#pre-trained-models\n",
    "\n",
    "- Paper Yolo v4: https://arxiv.org/abs/2004.10934\n",
    "- More details: [medium link](https://medium.com/@alexeyab84/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe?source=friends_link&sk=6039748846bbcf1d960c3061542591d7)\n",
    "- Manual: https://github.com/AlexeyAB/darknet/wiki\n",
    "- Result : https://www.youtube.com/user/pjreddie/videos <br>\n",
    "<img src=\"resource/opencv_dnn.gif\" style=\"width:500px\"></img>\n",
    "<br>\n",
    "<img src=\"resource/82835867-f1c62380-9ecd-11ea-9134-1598ed2abc4b.png\" style=\"width:700px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Yolo DNN\n",
    "\n",
    "- Required files :\n",
    "    - `.names` file\n",
    "    - `.cfg` file\n",
    "    - `.weights` file  \n",
    "- **cfg-files** - are structures of neural networks: https://github.com/AlexeyAB/darknet/tree/master/cfg\n",
    "- **weights-files** - are weights for correspond cfg-file, can be downloaded from: https://pjreddie.com/darknet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read class names from `.names` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesFile = \"yolo/plate_number/plate_number.names\"\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "    \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load `.cfg` and `.weights` using `cv2.dnn.readNetFromDarknet()`\n",
    "- Download `.weights` file from [this](https://drive.google.com/file/d/1vXjIoRWY0aIpYfhj3TnPUGdmJoHnWaOc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfiguration = \"yolo/plate_number/plate_number_yolov3.cfg\"\n",
    "modelWeights = \"yolo/plate_number/plate_number_yolov3.weights\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV DNN Backend\n",
    "- Set OpenCV DNN Backend using `.setPreferableBackend(backend_type)`\n",
    "- where `backend_type` :\n",
    "    - `cv2.dnn.DNN_BACKEND_DEFAULT`\n",
    "    - `cv2.dnn.DNN_BACKEND_VKOM`\n",
    "    - `cv2.dnn.DNN_BACKEND_HALIDE`\n",
    "    - `cv2.dnn.DNN_BACKEND_OPENCV`\n",
    "    - `cv2.dnn.DNN_BACKEND_INFERENCE_ENGINE`\n",
    "      \n",
    "#### OpenCV DNN Target\n",
    "- Set OpenCV DNN Target using `.setPreferableTarget(target_type)`\n",
    "- where `target_type` :\n",
    "    - `cv2.dnn.DNN_TARGET_CPU`\n",
    "    - `cv2.dnn.DNN_TARGET_MYRIAD`\n",
    "    - `cv2.dnn.DNN_TARGET_OPENCL`\n",
    "    - `cv2.dnn.DNN_TARGET_FPGA`\n",
    "    - `cv2.dnn.DNN_TARGET_VULKAN`\n",
    "    - `cv2.dnn.DNN_TARGET_CUDA` > OpenCV 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert image to blob using `cv2.dnn.blobFromImage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpWidth = 416      # Width of network's input image\n",
    "inpHeight = 416     # Height of network's input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"data/plat-nomor-2.jpg\")\n",
    "blob = cv2.dnn.blobFromImage(\n",
    "                        frame, \n",
    "                        1/255, \n",
    "                        (inpWidth, inpHeight), \n",
    "                        [0, 0, 0],\n",
    "                        1, \n",
    "                        crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(blob), blob.shape, blob.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape, frame.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Output layer using `.getUnconnectedOutLayersNames()` from `net` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set blob to input network using `.setInput()` on `net` object\n",
    "- Do forward pass and get output using `.forward()` on `net` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "outs = net.forward(layerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for out in outs:\n",
    "frame_h, frame_w, frame_c = frame.shape\n",
    "classIds = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        classId = np.argmax(scores)\n",
    "        confidence = scores[classId]\n",
    "        c_x = int(detection[0] * frame_w)\n",
    "        c_y = int(detection[1] * frame_h)\n",
    "        w = int(detection[2] * frame_w)\n",
    "        h = int(detection[3] * frame_h)\n",
    "        x = int(c_x - w / 2)\n",
    "        y = int(c_y - h / 2)\n",
    "        classIds.append(classId)\n",
    "        confidences.append(float(confidence))\n",
    "        boxes.append([x, y, w, h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find Non maximum supression (NMS) from boxes using `cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confThreshold = 0.5  # confidence level threshold\n",
    "nmsThreshold = 0.4 # NMS threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    box = boxes[i]\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imshow(\"frame\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap all into function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPred(classId, conf, left, top, right, bottom):\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (255, 0, 255), 2)\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s: %s' % (classes[classId], label)\n",
    "\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (max(right, left + labelSize[0]), top + baseLine), (255, 0, 255), -1)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n",
    "\n",
    "def postprocess(frame, outs):\n",
    "    frame_h, frame_w, frame_c = frame.shape\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:        \n",
    "                scores = detection[5:]\n",
    "                classId = np.argmax(scores)\n",
    "                confidence = scores[classId]\n",
    "                c_x = int(detection[0] * frame_w)\n",
    "                c_y = int(detection[1] * frame_h)\n",
    "                w = int(detection[2] * frame_w)\n",
    "                h = int(detection[3] * frame_h)\n",
    "                x = int(c_x - w / 2)\n",
    "                y = int(c_y - h / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left,\n",
    "                 top, left + width, top + height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_inf_time(frame, label, left =25, top=50):\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 255, 255), -1)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data/\" \n",
    "layerOutput = net.getUnconnectedOutLayersNames()\n",
    "for filename in os.listdir(dataset):\n",
    "    frame = cv2.imread(os.path.join(dataset, filename))\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        frame, 1/255, (inpWidth, inpHeight), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layerOutput)\n",
    "\n",
    "    postprocess(frame, outs)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f s' % (t / cv2.getTickFrequency())\n",
    "\n",
    "    frame = draw_inf_time(frame, label)\n",
    "    \n",
    "    cv2.imshow(\"out\", frame)\n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"cars_on_the_road_2.mp4\")\n",
    "while cap.isOpened :\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        continue\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        frame, 1/255, (inpWidth, inpHeight), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "    postprocess(frame, outs)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f s' % (t / cv2.getTickFrequency())\n",
    "    cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow(\"out\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Yolo Using Your Custom Dataset\n",
    "\n",
    "- **Prepare Dataset** : 100 image car (just for testing, in real case, need a lot of data)\n",
    "- **Dataset Annotation** : To annotante dataset using Yolo Format, use this desktop app : **[LabelImg]( https://github.com/tzutalin/labelImg)**\n",
    "<img src=\"resource/demo3.jpg\" style=\"width:600px\"></img>\n",
    "- **Train Model** on Colab ( https://colab.research.google.com/drive/1lTGZsfMaGUpBG4inDIQwIJVW476ibXk_#scrollTo=WewV3jU3B4Eo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
